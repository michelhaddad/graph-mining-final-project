{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from utils.artist_features import spotify_client, artist_features, related_artists\n",
    "from collections import defaultdict\n",
    "from queue import Queue\n",
    "import pickle\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collecting artists ids from daily charts and playlists"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get daily charts\n",
    "streams = pd.read_csv('../data/daily_charts.csv')\n",
    "\n",
    "# iterate over files in playlist folder\n",
    "playlists_data = pd.DataFrame()\n",
    "for filename in os.scandir('../data/playlists'):\n",
    "    if filename.is_file():\n",
    "        playlists_data = pd.concat([playlists_data, pd.read_csv(filename)], ignore_index=True)\n",
    "\n",
    "playlists_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "# Get unique artist ids\n",
    "\n",
    "artists_from_streams = streams['artists'].apply(lambda x: literal_eval(x)['id']).tolist()\n",
    "main_artists_from_playlists = playlists_data['id'].tolist()\n",
    "neighbors_artists = playlists_data['neighbours'].apply(lambda x: literal_eval(x)).tolist()\n",
    "neighbors_artists = reduce(operator.concat, neighbors_artists)\n",
    "\n",
    "# artists_ids = set(artists_from_streams) | set(main_artists_from_playlists) | set(neighbors_artists)\n",
    "artists_ids = set(neighbors_artists)\n",
    "print('Unique artists: %d' % len(artists_ids))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def dict_to_df(dictionary):\n",
    "    return pd.DataFrame([list(dictionary.values())], columns=list(dictionary.keys()))\n",
    "\n",
    "client_id = '7641b1dcfa894b9e97d9419d50e29c45'\n",
    "client_secret = 'a7a93ef6f8354a349374896772bf752b'\n",
    "sp = spotify_client(client_id, client_secret)\n",
    "\n",
    "# We need to set apart the artists we haven't encountered before to fetch their data\n",
    "artists_with_data = set()\n",
    "\n",
    "# Store the links between artists\n",
    "artist_links = defaultdict(set)\n",
    "\n",
    "# TODO change to 10k\n",
    "# We want to gather the related artists for a maximum of 10k artists (to reduce calls to the Spotify API)\n",
    "artist_queue_limit = 5000\n",
    "artist_count = 1\n",
    "artist_queue = Queue()\n",
    "\n",
    "# Keep dictionaries to save progress\n",
    "artists_features = {}\n",
    "artists_related_artists = {}\n",
    "# file = open('../data/tmp/af.pickle', 'rb')\n",
    "# artists_features = pickle.load(file)\n",
    "# file.close()\n",
    "#\n",
    "# file = open('../data/tmp/ar.pickle', 'rb')\n",
    "# artists_related_artists = pickle.load(file)\n",
    "# file.close()\n",
    "\n",
    "# Filling the queue with artists that appeared in the 2020 charts\n",
    "for id in artists_ids:\n",
    "    artist_queue.put(id)\n",
    "    break\n",
    "\n",
    "count = 0\n",
    "artists_info = pd.DataFrame()\n",
    "while not artist_queue.empty():\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print('Dequeued artist %d' % count)\n",
    "        file = open('../data/tmp/af.pickle', 'wb')\n",
    "        pickle.dump(artists_features, file)\n",
    "        file.close()\n",
    "        file = open('../data/tmp/ar.pickle', 'wb')\n",
    "        pickle.dump(artists_related_artists, file)\n",
    "        file.close()\n",
    "    artist_id = artist_queue.get()\n",
    "\n",
    "    # Save information for current artist\n",
    "    if artist_id not in artists_features:\n",
    "        artist_data = artist_features(sp, artist_id)\n",
    "        artists_features[artist_id] = artist_data\n",
    "    else:\n",
    "        artist_data = artists_features[artist_id]\n",
    "\n",
    "\n",
    "    if artist_id not in artists_with_data:\n",
    "        artists_info = pd.concat([artists_info, dict_to_df(artist_data)], ignore_index=True)\n",
    "        artists_with_data.add(artist_id)\n",
    "\n",
    "    # Go through related artists\n",
    "    if artist_id not in artists_related_artists:\n",
    "        rel_artists = related_artists(sp, artist_id)\n",
    "        artists_related_artists[artist_id] = rel_artists\n",
    "    else:\n",
    "        rel_artists = artists_related_artists[artist_id]\n",
    "\n",
    "    for related_artist in rel_artists:\n",
    "        # Add the related artist in the links of the current artist\n",
    "        artist_links[artist_id].add(related_artist['id'])\n",
    "\n",
    "        if related_artist['id'] in artists_with_data:\n",
    "            continue\n",
    "\n",
    "        # Save information for related artist\n",
    "        artists_info = pd.concat([artists_info, dict_to_df(related_artist)], ignore_index=True)\n",
    "        artists_with_data.add(related_artist['id'])\n",
    "\n",
    "        if artist_count < artist_queue_limit:\n",
    "            artist_queue.put(related_artist['id'])\n",
    "        artist_count += 1\n",
    "\n",
    "artists_info['followers'] = artists_info['followers'].astype(int)\n",
    "artists_info['popularity'] = artists_info['popularity'].astype(int)\n",
    "artists_info.to_csv('../data/artist_info.csv', index=False)\n",
    "\n",
    "artist_links_file = open(\"../data/artist_links.pickle\", \"wb\")\n",
    "pickle.dump(artist_links, artist_links_file)\n",
    "artist_links_file.close()\n",
    "\n",
    "print('Total number of artists: %d' % len(artists_with_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the Adjacency Matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of adjacency matrix: 684 x 684\n",
      "[[0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Load artist links\n",
    "artist_links_file = open(\"../data/artist_links.pickle\", \"rb\")\n",
    "artist_links = pickle.load(artist_links_file)\n",
    "artist_links_file.close()\n",
    "\n",
    "# Combine all artists\n",
    "artists = pd.read_csv('../data/artist_info.csv')\n",
    "\n",
    "adjacency = np.zeros((artists.shape[0], artists.shape[0]))\n",
    "idToIndexMap = {}\n",
    "\n",
    "# Since the artist links actually use the Spotify ID and not the index in the adjacency matrix,\n",
    "# we need to map the spotify id to the index\n",
    "for index, row in artists.iterrows():\n",
    "    idToIndexMap[row['id']] = index\n",
    "\n",
    "# Loop through all artists fill adjacency matrix with one in case of a relation\n",
    "for artist_id, rel_artists in artist_links.items():\n",
    "    artist_index = idToIndexMap[artist_id]\n",
    "    for related_artist in rel_artists:\n",
    "        related_artist_index = idToIndexMap[related_artist]\n",
    "        adjacency[artist_index, related_artist_index] = 1\n",
    "\n",
    "# Save id to index map for later\n",
    "id_to_index_file = open(\"../data/id_to_index.pickle\", \"wb\")\n",
    "pickle.dump(idToIndexMap, id_to_index_file)\n",
    "id_to_index_file.close()\n",
    "\n",
    "print('Size of adjacency matrix: %d x %d' % adjacency.shape)\n",
    "print(adjacency)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to sparse matrix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The adjacency matrix has 2000 non-zero elements, this is equivalent to the number of edges\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sparse\n",
    "\n",
    "sparse_adj = sparse.csc_matrix(adjacency)\n",
    "print('The adjacency matrix has %d non-zero elements, this is equivalent to the number of edges' % sparse_adj.nnz)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}